{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "589dcfd3-6a85-4fe6-9745-3ff5ab24b44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location 7570 (Toronto Downtown) has 2 sensors matching target pollutants\n",
      "Location 921005 (Downtown Vancouver) has 1 sensors matching target pollutants\n",
      "Location 277971 (Edmonton Central Eas) has 2 sensors matching target pollutants\n",
      "Location 1275379 (Ottawa Downtown) has 2 sensors matching target pollutants\n",
      "Location 8809 (Calgary Central2) has 2 sensors matching target pollutants\n",
      "Progress: 5/58 locations processed (8.6%) (9 total tasks queued, 0 completed)\n",
      "Location 8477 (St-Dominique) has 1 sensors matching target pollutants\n",
      "Location 1572 (Brandon) has 2 sensors matching target pollutants\n",
      "Location 754 (FREDERICTON) has 2 sensors matching target pollutants\n",
      "Location 748 (CHARLOTTETOWN) has 2 sensors matching target pollutants\n",
      "Location 958 (Saskatoon) has 2 sensors matching target pollutants\n",
      "Progress: 10/58 locations processed (17.2%) (18 total tasks queued, 0 completed)\n",
      "Location 589 (Regina) has 2 sensors matching target pollutants\n",
      "Location 1274948 (Thunder Bay) has 2 sensors matching target pollutants\n",
      "Location 922 (Bonner Lake) has 2 sensors matching target pollutants\n",
      "Location 236033 (Radisson) has 2 sensors matching target pollutants\n",
      "Location 982 (Chapais) has 1 sensors matching target pollutants\n",
      "Progress: 15/58 locations processed (25.9%) (27 total tasks queued, 0 completed)\n",
      "Location 476 (Rouyn-Noranda - Parc) has 2 sensors matching target pollutants\n",
      "Location 1285344 (SPARTAN - Halifax) has 1 sensors matching target pollutants\n",
      "Location 230097 (Kelowna KLO Road) has 2 sensors matching target pollutants\n",
      "Location 1381 (Winnipeg_Ellens) has 2 sensors matching target pollutants\n",
      "Location 8910 (Wood Buffalo Park) has 1 sensors matching target pollutants\n",
      "Progress: 20/58 locations processed (34.5%) (35 total tasks queued, 0 completed)\n",
      "Location 972 (Snare Rapids) has 1 sensors matching target pollutants\n",
      "Location 2895671 (Con Area Yellowknife) has 1 sensors matching target pollutants\n",
      "Location 509 (Fort Chipewyan) has 2 sensors matching target pollutants\n",
      "Location 921002 (Buffalo Narrows) has 2 sensors matching target pollutants\n",
      "Location 8717 (PRINCE ALBERT) has 2 sensors matching target pollutants\n",
      "Progress: 25/58 locations processed (43.1%) (43 total tasks queued, 0 completed)\n",
      "Location 3010440 (Greystone Heights) has 1 sensors matching target pollutants\n",
      "Location 2939447 (Pickle Lake) has 1 sensors matching target pollutants\n",
      "Location 2064 (Experimental Lakes) has 1 sensors matching target pollutants\n",
      "Location 450 (R�s. Faun. Ashuapmus) has 2 sensors matching target pollutants\n",
      "Location 528 (Mont-Saint-Michel) has 2 sensors matching target pollutants\n",
      "Progress: 30/58 locations processed (51.7%) (50 total tasks queued, 0 completed)\n",
      "Location 3009455 (Beausejour) has 1 sensors matching target pollutants\n",
      "Location 1415 (Flin Flon) has 2 sensors matching target pollutants\n",
      "Location 8735 (Pinehouse Lake) has 1 sensors matching target pollutants\n",
      "Location 3036183 (Town of Peace River) has 1 sensors matching target pollutants\n",
      "Location 8640 (Joussard) has 2 sensors matching target pollutants\n",
      "Progress: 35/58 locations processed (60.3%) (57 total tasks queued, 0 completed)\n",
      "Location 456 (Beaverlodge) has 2 sensors matching target pollutants\n",
      "Location 8567 (FORT ST JOHN LEARNIN) has 2 sensors matching target pollutants\n",
      "Location 2272 (PRG Plaza 400) has 2 sensors matching target pollutants\n",
      "Location 270714 (Quesnel Johnston Ave) has 2 sensors matching target pollutants\n",
      "Location 224177 (Whitehorse NAPS) has 2 sensors matching target pollutants\n",
      "Progress: 40/58 locations processed (69.0%) (67 total tasks queued, 0 completed)\n",
      "Location 7975 (Vanderhoof Courthous) has 1 sensors matching target pollutants\n",
      "Location 268736 (Burns Lake Fire Cent) has 1 sensors matching target pollutants\n",
      "Location 1138 (Houston Firehall) has 1 sensors matching target pollutants\n",
      "Location 230091 (Smithers Muheim Memo) has 2 sensors matching target pollutants\n",
      "Location 8755 (Courtenay Elementary) has 2 sensors matching target pollutants\n",
      "Progress: 45/58 locations processed (77.6%) (74 total tasks queued, 0 completed)\n",
      "Location 1275800 (Sault Ste Marie) has 2 sensors matching target pollutants\n",
      "Location 2873228 (Searchmont) has 1 sensors matching target pollutants\n",
      "Location 8867 (Sudbury) has 2 sensors matching target pollutants\n",
      "Location 1289474 (North Bay) has 2 sensors matching target pollutants\n",
      "Location 1275789 (Dorset) has 2 sensors matching target pollutants\n",
      "Progress: 50/58 locations processed (86.2%) (83 total tasks queued, 0 completed)\n",
      "Location 1275797 (Parry Sound) has 2 sensors matching target pollutants\n",
      "Location 8652 (Kingston) has 2 sensors matching target pollutants\n",
      "Location 519 (Notre-Dame-du-Rosair) has 2 sensors matching target pollutants\n",
      "Location 236027 (Auclair) has 2 sensors matching target pollutants\n",
      "Location 744 (BATHURST) has 2 sensors matching target pollutants\n",
      "Progress: 55/58 locations processed (94.8%) (93 total tasks queued, 0 completed)\n",
      "Location 326608 (FIREHALL-LABRADORCIT) has 2 sensors matching target pollutants\n",
      "Location 1185 (Goose Bay) has 1 sensors matching target pollutants\n",
      "Location 2037 (SYDNEY) has 2 sensors matching target pollutants\n",
      "Progress: 58/58 locations processed (100.0%) (98 total tasks queued, 0 completed)\n",
      "Task Progress: 5/98 tasks completed (5.1%)\n",
      "Task Progress: 10/98 tasks completed (10.2%)\n",
      "Task Progress: 15/98 tasks completed (15.3%)\n",
      "Task Progress: 20/98 tasks completed (20.4%)\n",
      "Task Progress: 25/98 tasks completed (25.5%)\n",
      "Task Progress: 30/98 tasks completed (30.6%)\n",
      "Task Progress: 35/98 tasks completed (35.7%)\n",
      "Task Progress: 40/98 tasks completed (40.8%)\n",
      "Task Progress: 45/98 tasks completed (45.9%)\n",
      "Task Progress: 50/98 tasks completed (51.0%)\n",
      "Task Progress: 55/98 tasks completed (56.1%)\n",
      "Task Progress: 60/98 tasks completed (61.2%)\n",
      "Task Progress: 65/98 tasks completed (66.3%)\n",
      "Task Progress: 70/98 tasks completed (71.4%)\n",
      "Task Progress: 75/98 tasks completed (76.5%)\n",
      "Task Progress: 80/98 tasks completed (81.6%)\n",
      "Task Progress: 85/98 tasks completed (86.7%)\n",
      "Task Progress: 90/98 tasks completed (91.8%)\n",
      "Task Progress: 95/98 tasks completed (96.9%)\n",
      "Task Progress: 98/98 tasks completed (100.0%)\n",
      "Monthly data collection complete. Results saved to air_quality_monthly_data.csv\n",
      "Execution time: 263.38 seconds\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "\n",
    "# API Configuration\n",
    "API_KEY = \"3b0245765d215cb08bd25591a879398c00b8f65e975f7b77f96263d3598788f2\"\n",
    "locations_url = \"https://api.openaq.org/v3/locations/\"\n",
    "measurements_url = \"https://api.openaq.org/v3/sensors/\"\n",
    "headers = {\"X-API-Key\": API_KEY}\n",
    "\n",
    "# List of city location IDs\n",
    "locations = [7570, 921005, 277971, 1275379, 8809, 8477, 1572, 754, 748, 958, 589, 1274948, 922, 236033, 982, 476,\n",
    "             1285344, 230097, 1381, 8910, 972, 2895671, 509, 921002, 8717, 3010440, 2939447, 2064, 450, 528, 3009455,\n",
    "             1415, 8735, 3036183, 8640, 456, 8567, 2272, 270714, 224177, 7975, 268736, 1138, 230091, 8755,1275800,\n",
    "             2873228, 8867, 1289474, 1275789, 1275797, 8652, 519, 236027, 744,326608, 1185, 2037]\n",
    "\n",
    "# List of pollutants to focus on (wildfire-related, matching API values)\n",
    "target_pollutants = [\"pm2.5\", \"o₃\"]  # Updated to include only pm2.5 and o₃\n",
    "\n",
    "# Shared data\n",
    "all_data = []\n",
    "\n",
    "# Track requests for hourly limit\n",
    "request_count = 0\n",
    "hour_start_time = time.time()\n",
    "\n",
    "# Progress tracking\n",
    "locations_processed = 0\n",
    "total_tasks = 0\n",
    "tasks_completed = 0\n",
    "\n",
    "def fetch_location_data(location_id):\n",
    "    \"\"\"Fetch location details and return sensor tasks.\"\"\"\n",
    "    global request_count, hour_start_time, locations_processed, total_tasks\n",
    "    url = f\"{locations_url}{location_id}\"\n",
    "    tasks = []\n",
    "    try:\n",
    "        # Check hourly limit\n",
    "        current_time = time.time()\n",
    "        if current_time - hour_start_time >= 3600:\n",
    "            request_count = 0\n",
    "            hour_start_time = current_time\n",
    "        if request_count >= 2000:\n",
    "            sleep_time = 3600 - (current_time - hour_start_time)\n",
    "            print(f\"Hourly limit reached. Sleeping for {sleep_time:.2f} seconds...\")\n",
    "            time.sleep(sleep_time)\n",
    "            request_count = 0\n",
    "            hour_start_time = time.time()\n",
    "        request_count += 1\n",
    "\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        location_result = response.json().get(\"results\", [])[0]\n",
    "        \n",
    "        city_name = location_result.get(\"name\", \"Unknown\")\n",
    "        latitude = location_result.get(\"coordinates\", {}).get(\"latitude\", None)\n",
    "        longitude = location_result.get(\"coordinates\", {}).get(\"longitude\", None)\n",
    "        \n",
    "        for sensor in location_result.get(\"sensors\", []):\n",
    "            sensor_id = sensor[\"id\"]\n",
    "            param_name = sensor[\"parameter\"][\"displayName\"].lower()\n",
    "            unit = sensor[\"parameter\"][\"units\"]\n",
    "            if param_name in target_pollutants:\n",
    "                tasks.append((location_id, city_name, latitude, longitude, sensor_id, param_name, unit))\n",
    "        \n",
    "        # Log the number of matching sensors\n",
    "        num_sensors = len(tasks)\n",
    "        print(f\"Location {location_id} ({city_name}) has {num_sensors} sensors matching target pollutants\")\n",
    "        total_tasks += num_sensors\n",
    "        \n",
    "        locations_processed += 1\n",
    "        # Log progress every 5 locations\n",
    "        if locations_processed % 5 == 0 or locations_processed == len(locations):\n",
    "            progress = (locations_processed / len(locations)) * 100\n",
    "            print(f\"Progress: {locations_processed}/{len(locations)} locations processed ({progress:.1f}%) \"\n",
    "                  f\"({total_tasks} total tasks queued, {tasks_completed} completed)\")\n",
    "        \n",
    "        time.sleep(1)  # 1 request per second\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching location {location_id}: {e}\")\n",
    "    return tasks\n",
    "\n",
    "def fetch_measurements(location_id, city_name, latitude, longitude, sensor_id, param_name, unit):\n",
    "    \"\"\"Fetch monthly measurements for a specific sensor with retry logic.\"\"\"\n",
    "    global request_count, hour_start_time, tasks_completed\n",
    "    meas_url = (f\"{measurements_url}{sensor_id}/hours/monthly?\"\n",
    "                f\"datetime_from=2014-01-01T00:00:00Z&datetime_to=2025-03-06T12:32:00Z&limit=200&page=1\")\n",
    "    max_retries = 3\n",
    "    retry_delay = 1\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Check hourly limit\n",
    "            current_time = time.time()\n",
    "            if current_time - hour_start_time >= 3600:\n",
    "                request_count = 0\n",
    "                hour_start_time = current_time\n",
    "            if request_count >= 2000:\n",
    "                sleep_time = 3600 - (current_time - hour_start_time)\n",
    "                print(f\"Hourly limit reached. Sleeping for {sleep_time:.2f} seconds...\")\n",
    "                time.sleep(sleep_time)\n",
    "                request_count = 0\n",
    "                hour_start_time = time.time()\n",
    "            request_count += 1\n",
    "\n",
    "            response = requests.get(meas_url, headers=headers, timeout=10)\n",
    "            if response.status_code == 429:\n",
    "                print(f\"429 error for sensor {sensor_id}. Retrying in {retry_delay} seconds...\")\n",
    "                time.sleep(retry_delay)\n",
    "                retry_delay *= 2\n",
    "                continue\n",
    "            response.raise_for_status()\n",
    "            meas_data = response.json().get(\"results\", [])\n",
    "            \n",
    "            for month_data in meas_data:\n",
    "                monthly_value = month_data.get(\"value\", \"N/A\")\n",
    "                period_from = month_data[\"period\"][\"datetimeFrom\"][\"utc\"]\n",
    "                period_to = month_data[\"period\"][\"datetimeTo\"][\"utc\"]\n",
    "                summary = month_data.get(\"summary\", {})\n",
    "                \n",
    "                all_data.append({\n",
    "                    \"City\": city_name,\n",
    "                    \"Latitude\": latitude,\n",
    "                    \"Longitude\": longitude,\n",
    "                    \"Sensor Parameter\": param_name,\n",
    "                    \"Unit\": unit,\n",
    "                    \"Month Start (UTC)\": period_from,\n",
    "                    \"Month End (UTC)\": period_to,\n",
    "                    \"Monthly Average\": monthly_value,\n",
    "                    \"Minimum Value\": summary.get(\"min\", \"N/A\"),\n",
    "                    \"Maximum Value\": summary.get(\"max\", \"N/A\"),\n",
    "                    \"Median Value\": summary.get(\"median\", \"N/A\"),\n",
    "                    \"Standard Deviation\": summary.get(\"sd\", \"N/A\")\n",
    "                })\n",
    "            tasks_completed += 1\n",
    "            # Log task completion progress\n",
    "            if tasks_completed % 5 == 0 or tasks_completed == total_tasks:\n",
    "                progress = (tasks_completed / total_tasks) * 100 if total_tasks > 0 else 0\n",
    "                print(f\"Task Progress: {tasks_completed}/{total_tasks} tasks completed ({progress:.1f}%)\")\n",
    "            time.sleep(1)  # 1 request per second\n",
    "            break\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            if isinstance(e, requests.exceptions.HTTPError) and e.response.status_code == 429:\n",
    "                print(f\"429 error for sensor {sensor_id}. Retrying in {retry_delay} seconds...\")\n",
    "                time.sleep(retry_delay)\n",
    "                retry_delay *= 2\n",
    "            else:\n",
    "                print(f\"Error fetching measurements for sensor {sensor_id}: {e}\")\n",
    "                break\n",
    "\n",
    "def main():\n",
    "    global all_data\n",
    "    \n",
    "    # Fetch location data and collect sensor tasks\n",
    "    sensor_tasks = []\n",
    "    for location_id in locations:\n",
    "        tasks = fetch_location_data(location_id)\n",
    "        sensor_tasks.extend(tasks)\n",
    "\n",
    "    # Fetch measurements sequentially\n",
    "    for task in sensor_tasks:\n",
    "        location_id, city_name, latitude, longitude, sensor_id, param_name, unit = task\n",
    "        fetch_measurements(location_id, city_name, latitude, longitude, sensor_id, param_name, unit)\n",
    "\n",
    "    # Convert to Pandas DataFrame\n",
    "    df = pd.DataFrame(all_data)\n",
    "    df['Month Start (UTC)'] = pd.to_datetime(df['Month Start (UTC)'])\n",
    "    df['Month End (UTC)'] = pd.to_datetime(df['Month End (UTC)'])\n",
    "\n",
    "    # Save to CSV\n",
    "    df.to_csv(\"air_quality_monthly_data.csv\", index=False)\n",
    "    print(\"Monthly data collection complete. Results saved to air_quality_monthly_data.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    main()\n",
    "    end_time = time.time()\n",
    "    print(f\"Execution time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2deec39d-6e63-4d94-b7a6-55467099af6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Correlation between PM2.5 and O₃: 0.09194197860531834\n",
      "\n",
      "Correlation by City and Year:\n",
      "City             Month Start (UTC)  Sensor Parameter\n",
      "Auclair          2021               pm2.5                    NaN\n",
      "                 2022               pm2.5              -0.180393\n",
      "                 2023               pm2.5              -0.464529\n",
      "                 2024               pm2.5              -0.692740\n",
      "BATHURST         2018               pm2.5              -0.450174\n",
      "                                                          ...   \n",
      "Winnipeg_Ellens  2019               pm2.5               0.212509\n",
      "                 2020               pm2.5               0.399999\n",
      "                 2021               pm2.5              -0.454287\n",
      "                 2022               pm2.5              -0.514022\n",
      "                 2023               pm2.5               0.243698\n",
      "Name: o₃, Length: 166, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"air_quality_monthly_data.csv\")\n",
    "df['Month Start (UTC)'] = pd.to_datetime(df['Month Start (UTC)'])\n",
    "\n",
    "# Filter wildfire seasons (May-Sep, 2018-2024)\n",
    "wildfire_df = df[df['Month Start (UTC)'].dt.month.isin([5, 6, 7, 8, 9])]\n",
    "wildfire_df = wildfire_df[wildfire_df['Month Start (UTC)'].dt.year.between(2018, 2024)]\n",
    "\n",
    "# Pivot to pair PM2.5 and O₃\n",
    "pivot_df = wildfire_df.pivot_table(index=['City', 'Month Start (UTC)'], \n",
    "                                  columns='Sensor Parameter', \n",
    "                                  values='Monthly Average').dropna()\n",
    "\n",
    "# Calculate overall correlation\n",
    "correlations = pivot_df.corr(method='pearson').loc['pm2.5', 'o₃']\n",
    "\n",
    "# Per city and year correlation\n",
    "# Group by City and year, then compute correlation between pm2.5 and o₃\n",
    "city_year_corr = pivot_df.groupby(['City', pivot_df.index.get_level_values('Month Start (UTC)').year])[['pm2.5', 'o₃']].corr().iloc[0::2, -1]\n",
    "\n",
    "print(\"Overall Correlation between PM2.5 and O₃:\", correlations)\n",
    "print(\"\\nCorrelation by City and Year:\")\n",
    "print(city_year_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c5cf3f-1129-466d-b78c-ffa5bad2032e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
